# Bristlenose Configuration
# Copy this file to .env and fill in your values

# LLM Provider: "anthropic" (Claude), "openai" (ChatGPT), "azure", "google" (Gemini), or "local" (Ollama)
# You only need one cloud provider key â€” or use "local" for free, no-key analysis
BRISTLENOSE_LLM_PROVIDER=anthropic

# API Keys -- set the one matching your provider
# Claude key from console.anthropic.com
BRISTLENOSE_ANTHROPIC_API_KEY=
# ChatGPT key from platform.openai.com
BRISTLENOSE_OPENAI_API_KEY=
# Gemini key from aistudio.google.com/apikey (budget option, ~$0.20/study)
BRISTLENOSE_GOOGLE_API_KEY=

# Azure OpenAI (enterprise) -- all three are required for --llm azure
# BRISTLENOSE_AZURE_API_KEY=
# BRISTLENOSE_AZURE_ENDPOINT=https://your-resource.openai.azure.com/
# BRISTLENOSE_AZURE_DEPLOYMENT=your-deployment-name
# BRISTLENOSE_AZURE_API_VERSION=2024-10-21

# Local AI (Ollama) -- no key needed, just install Ollama
# BRISTLENOSE_LOCAL_URL=http://localhost:11434/v1
# BRISTLENOSE_LOCAL_MODEL=llama3.2:3b

# LLM Model (default: claude-sonnet-4-20250514)
# BRISTLENOSE_LLM_MODEL=claude-sonnet-4-20250514

# Whisper transcription backend: auto, mlx (Apple Silicon GPU), faster-whisper (CUDA/CPU)
# "auto" detects your hardware and picks the best option
# BRISTLENOSE_WHISPER_BACKEND=auto

# Whisper model size: tiny, base, small, medium, large-v3, large-v3-turbo
# BRISTLENOSE_WHISPER_MODEL=large-v3-turbo

# Whisper language (default: en)
# BRISTLENOSE_WHISPER_LANGUAGE=en

# Whisper device: cpu, cuda, auto (faster-whisper only, ignored when using mlx)
# BRISTLENOSE_WHISPER_DEVICE=auto

# Whisper compute type: int8, float16, float32 (faster-whisper only)
# BRISTLENOSE_WHISPER_COMPUTE_TYPE=int8
